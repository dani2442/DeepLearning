{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Logisitc_Regression_TF_2.0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dani2442/DeepLearning/blob/master/Logisitc_Regression_TF_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moB4tpEHxKB3"
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z208sQ-d2_x"
      },
      "source": [
        "## Import the required Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YT4KWH2bEh5"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.estimator import LinearClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqipGnAxd7dS"
      },
      "source": [
        "## Load and configure the Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixeEGkOMYfG0"
      },
      "source": [
        "col_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "target_dimensions = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "training_data_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_data_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "training = pd.read_csv(training_data_path, names=col_names, header=0)\n",
        "training = training[training['Species'] >= 1]\n",
        "training['Species'] = training['Species'].replace([1,2], [0,1])\n",
        "test = pd.read_csv(test_data_path, names=col_names, header=0)\n",
        "test = test[test['Species'] >= 1]\n",
        "test['Species'] = test['Species'].replace([1,2], [0,1])\n",
        "\n",
        "training.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "iris_dataset = pd.concat([training, test], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN21hKEJr4u"
      },
      "source": [
        "iris_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ubs136WLNp"
      },
      "source": [
        "## Checking the relation between the variables using Pairplot and Correlation Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRKO_x8gWKv-"
      },
      "source": [
        "sb.pairplot(iris_dataset, diag_kind=\"kde\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbatgoGzfD5S"
      },
      "source": [
        "correlation_data = iris_dataset.corr()\n",
        "correlation_data.style.background_gradient(cmap='coolwarm', axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_eJiJzjfhSo"
      },
      "source": [
        "## Descriptive Statistics - Central Tendency and Dispersion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osfWwMtafEHy"
      },
      "source": [
        "stats = iris_dataset.describe()\n",
        "iris_stats = stats.transpose()\n",
        "iris_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ONfi8-VgGRQ"
      },
      "source": [
        "## Select the required columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mojmc51X4vCv"
      },
      "source": [
        "X_data = iris_dataset[[m for m in iris_dataset.columns if m not in ['Species']]]\n",
        "Y_data = iris_dataset[['Species']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj16Yg-XgK9O"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgDkB9NqqD1t"
      },
      "source": [
        "training_features , test_features ,training_labels, test_labels = train_test_split(X_data , Y_data , test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D940EkTxqqrE"
      },
      "source": [
        "print('No. of rows in Training Features: ', training_features.shape[0])\n",
        "print('No. of rows in Test Features: ', test_features.shape[0])\n",
        "print('No. of columns in Training Features: ', training_features.shape[1])\n",
        "print('No. of columns in Test Features: ', test_features.shape[1])\n",
        "\n",
        "print('No. of rows in Training Label: ', training_labels.shape[0])\n",
        "print('No. of rows in Test Label: ', test_labels.shape[0])\n",
        "print('No. of columns in Training Label: ', training_labels.shape[1])\n",
        "print('No. of columns in Test Label: ', test_labels.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abSKdhM71_In"
      },
      "source": [
        "stats = training_features.describe()\n",
        "stats = stats.transpose()\n",
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP_sRTRCgRUm"
      },
      "source": [
        "stats = test_features.describe()\n",
        "stats = stats.transpose()\n",
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHOZyiJ7Hs2H"
      },
      "source": [
        "def norm(x):\n",
        "  stats = x.describe()\n",
        "  stats = stats.transpose()\n",
        "  return (x - stats['mean']) / stats['std']\n",
        "\n",
        "normed_train_features = norm(training_features)\n",
        "normed_test_features = norm(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF3pQYwmgfky"
      },
      "source": [
        "## Build the Input Pipeline for TensorFlow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI1dTJcWpeVL"
      },
      "source": [
        "def feed_input(features_dataframe, target_dataframe, num_of_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_feed_function():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features_dataframe), target_dataframe))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(2000)\n",
        "    dataset = dataset.batch(batch_size).repeat(num_of_epochs)\n",
        "    return dataset\n",
        "  return input_feed_function\n",
        "\n",
        "train_feed_input = feed_input(normed_train_features, training_labels)\n",
        "train_feed_input_testing = feed_input(normed_train_features, training_labels, num_of_epochs=1, shuffle=False)\n",
        "test_feed_input = feed_input(normed_test_features, test_labels, num_of_epochs=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCw3Zh1Vovzf"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpYQHKmqy3--"
      },
      "source": [
        "feature_columns_numeric = [tf.feature_column.numeric_column(m) for m in training_features.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I85mYJ72rFz8"
      },
      "source": [
        "logistic_model = LinearClassifier(feature_columns=feature_columns_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ebRtr7rIXN"
      },
      "source": [
        "logistic_model.train(train_feed_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuCIeITNo_L7"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki_FevrGLCGb"
      },
      "source": [
        "train_predictions = logistic_model.predict(train_feed_input_testing)\n",
        "test_predictions = logistic_model.predict(test_feed_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfnd5pE2W2iX"
      },
      "source": [
        "train_predictions_series = pd.Series([p['classes'][0].decode(\"utf-8\")   for p in train_predictions])\n",
        "test_predictions_series = pd.Series([p['classes'][0].decode(\"utf-8\")   for p in test_predictions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqErzOxZMH67"
      },
      "source": [
        "train_predictions_df = pd.DataFrame(train_predictions_series, columns=['predictions'])\n",
        "test_predictions_df = pd.DataFrame(test_predictions_series, columns=['predictions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1QlGchTypw"
      },
      "source": [
        "training_labels.reset_index(drop=True, inplace=True)\n",
        "train_predictions_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "test_labels.reset_index(drop=True, inplace=True)\n",
        "test_predictions_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPemk9i7Mdgn"
      },
      "source": [
        "train_labels_with_predictions_df = pd.concat([training_labels, train_predictions_df], axis=1)\n",
        "test_labels_with_predictions_df = pd.concat([test_labels, test_predictions_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw2eAJvRwBuo"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAdgDDfxpgMc"
      },
      "source": [
        "def calculate_binary_class_scores(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred.astype('int64'))\n",
        "  precision = precision_score(y_true, y_pred.astype('int64'))\n",
        "  recall = recall_score(y_true, y_pred.astype('int64'))\n",
        "  return accuracy, precision, recall\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fjo8OZoqOb-"
      },
      "source": [
        "train_accuracy_score, train_precision_score, train_recall_score = calculate_binary_class_scores(training_labels, train_predictions_series)\n",
        "test_accuracy_score, test_precision_score, test_recall_score = calculate_binary_class_scores(test_labels, test_predictions_series)\n",
        "\n",
        "print('Training Data Accuracy (%) = ', round(train_accuracy_score*100,2))\n",
        "print('Training Data Precision (%) = ', round(train_precision_score*100,2))\n",
        "print('Training Data Recall (%) = ', round(train_recall_score*100,2))\n",
        "print('-'*50)\n",
        "print('Test Data Accuracy (%) = ', round(test_accuracy_score*100,2))\n",
        "print('Test Data Precision (%) = ', round(test_precision_score*100,2))\n",
        "print('Test Data Recall (%) = ', round(test_recall_score*100,2))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
