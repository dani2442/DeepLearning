{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Neural_Networks_Fashion_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dani2442/DeepLearning/blob/master/Copia_de_Neural_Networks_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMY_MVkEVvVk"
      },
      "source": [
        "**Basic Neural Network Implementation in TensorFlow 2.0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHB_vwWVXrZj"
      },
      "source": [
        "**About the dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeYuWEjfe9RM"
      },
      "source": [
        "Let us implement a simple neural network using TensorFlow 2.0. For this, we will make use of the Fashion MNIST dataset by Zalando (MIT License) which contains 70,000 images (in grayscale) in 10 different categories. The images are 28x28 pixels of individual articles of clothing with values ranging from 0 to 255 as shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seckBTs0fE95"
      },
      "source": [
        "![Fashion MNIST dataset](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7RC1ya2fXs8"
      },
      "source": [
        "Out of the total 70,000 images, 60,000 are used for training and remaining 10,000 for testing. The labels are integer arrays ranging from 0 to 9. The class names are not a part of the dataset and hence we need to include the below mapping while training/prediction:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH1CpmcSfdHp"
      },
      "source": [
        "Label\t-> Description\n",
        "\n",
        "0\t-> T-shirt/top\n",
        "\n",
        "1\t-> Trouser\n",
        "\n",
        "2\t-> Pullover\n",
        "\n",
        "3\t-> Dress\n",
        "\n",
        "4\t-> Coat\n",
        "\n",
        "5\t-> Sandal\n",
        "\n",
        "6\t-> Shirt\n",
        "\n",
        "7\t-> Sneaker\n",
        "\n",
        "8\t-> Bag\n",
        "\n",
        "9\t-> Ankle boot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Q51QeJknFy"
      },
      "source": [
        "# Create class_names list object for mapping labels to names\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnX3qP7aDc9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b323a79-86ae-4e15-a62a-84c24cc7a889"
      },
      "source": [
        "# Use the below code to make sure that you select TensorFlow 2.0 in Colab\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIb3JAnDDNng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1882dce1-9446-4007-80d3-ea2ab93fb0ac"
      },
      "source": [
        "# Install necessary modules\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as ks\n",
        "\n",
        "# Validating the TensorFlow version\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LNPDWFrDWyf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "705af8ed-e3a0-4deb-c481-4f618e14e208"
      },
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = ks.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Fhp6IClLn8"
      },
      "source": [
        "**Data Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhMQlj4yD1Gw"
      },
      "source": [
        "# Shape of Training and Test Set\n",
        "\n",
        "print('Training Images Dataset Shape: {}'.format(training_images.shape))\n",
        "print('No. of Training Images Dataset Labels: {}'.format(len(training_labels)))\n",
        "print('Test Images Dataset Shape: {}'.format(test_images.shape))\n",
        "print('No. of Test Images Dataset Labels: {}'.format(len(test_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckCUKXUbl22y"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTt1pqz0l6tp"
      },
      "source": [
        "As the pixel values range from 0 to 255, we have to scale these values to a range of 0 to 1 before feeding them to the model. We can scale these values (both for training and test datasets) by dividing the values by 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMZ1yl8FEI_n"
      },
      "source": [
        "training_images = training_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miCPDg1uvD8z"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKp_6degvwnX"
      },
      "source": [
        "We will be using the keras implementation to build the different layers of a NN. We will keep it simple by having only 1 hidden layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMLYMBi8EQUj"
      },
      "source": [
        "input_data_shape = (28, 28)\n",
        "hidden_activation_function = 'relu'\n",
        "output_activation_function = 'softmax'\n",
        "\n",
        "nn_model = models.Sequential()\n",
        "nn_model.add(ks.layers.Flatten(input_shape=input_data_shape, name='Input_layer'))\n",
        "nn_model.add(ks.layers.Dense(32, activation=hidden_activation_function, name='Hidden_layer'))\n",
        "nn_model.add(ks.layers.Dense(10, activation=output_activation_function, name='Output_layer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Paa3H8AmFYjP"
      },
      "source": [
        "nn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcp73o-7lkfo"
      },
      "source": [
        "Now, we will use an optimization function with the help of compile method. An Adam optimizer with objective function as sparse_categorical_crossentropy which optimzes for the accuracy metric can be built as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8-t_o0KZU_4"
      },
      "source": [
        "optimizer = 'adam'\n",
        "loss_function = 'sparse_categorical_crossentropy'\n",
        "metric = ['accuracy']\n",
        "nn_model.compile(optimizer=optimizer, loss=loss_function, metrics=metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q180LIrcZiQk"
      },
      "source": [
        "nn_model.fit(training_images, training_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXA1brtrmgdI"
      },
      "source": [
        "**Model Evaluation**\n",
        "\n",
        "1. Training Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRISUog8RNJF"
      },
      "source": [
        "training_loss, training_accuracy = nn_model.evaluate(training_images, training_labels)\n",
        "\n",
        "print('Training Data Accuracy {}'.format(round(float(training_accuracy),2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL_6AuJomqel"
      },
      "source": [
        "2. Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KNIAUSEFgPO"
      },
      "source": [
        "test_loss, test_accuracy = nn_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test Data Accuracy {}'.format(round(float(test_accuracy),2)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
