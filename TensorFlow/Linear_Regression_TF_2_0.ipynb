{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Linear_Regression_TF_2.0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dani2442/DeepLearning/blob/master/Linear_Regression_TF_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moB4tpEHxKB3"
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z208sQ-d2_x"
      },
      "source": [
        "## Import the required Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YT4KWH2bEh5"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as ks\n",
        "from tensorflow.estimator import LinearRegressor\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqipGnAxd7dS"
      },
      "source": [
        "## Load and configure the Boston Housing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixeEGkOMYfG0"
      },
      "source": [
        "boston_load = datasets.load_boston()\n",
        "\n",
        "feature_columns = boston_load.feature_names\n",
        "target_column = boston_load.target\n",
        "\n",
        "boston_data = pd.DataFrame(boston_load.data, columns=feature_columns).astype(np.float32)\n",
        "boston_data['MEDV'] = target_column.astype(np.float32)\n",
        "\n",
        "boston_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ubs136WLNp"
      },
      "source": [
        "## Checking the relation between the variables using Pairplot and Correlation Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRKO_x8gWKv-"
      },
      "source": [
        "sb.pairplot(boston_data, diag_kind=\"kde\", height=3, aspect=0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbatgoGzfD5S"
      },
      "source": [
        "correlation_data = boston_data.corr()\n",
        "correlation_data.style.background_gradient(cmap='coolwarm', axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_eJiJzjfhSo"
      },
      "source": [
        "## Descriptive Statistics - Central Tendency and Dispersion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osfWwMtafEHy"
      },
      "source": [
        "stats = boston_data.describe()\n",
        "boston_stats = stats.transpose()\n",
        "boston_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ONfi8-VgGRQ"
      },
      "source": [
        "## Select the required columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mojmc51X4vCv"
      },
      "source": [
        "X_data = boston_data[[i for i in boston_data.columns if i not in ['MEDV']]]\n",
        "Y_data = boston_data[['MEDV']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj16Yg-XgK9O"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgDkB9NqqD1t"
      },
      "source": [
        "training_features , test_features ,training_labels, test_labels = train_test_split(X_data , Y_data , test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D940EkTxqqrE"
      },
      "source": [
        "print('No. of rows in Training Features: ', training_features.shape[0])\n",
        "print('No. of rows in Test Features: ', test_features.shape[0])\n",
        "print('No. of columns in Training Features: ', training_features.shape[1])\n",
        "print('No. of columns in Test Features: ', test_features.shape[1])\n",
        "\n",
        "print('No. of rows in Training Label: ', training_labels.shape[0])\n",
        "print('No. of rows in Test Label: ', test_labels.shape[0])\n",
        "print('No. of columns in Training Label: ', training_labels.shape[1])\n",
        "print('No. of columns in Test Label: ', test_labels.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abSKdhM71_In"
      },
      "source": [
        "stats = training_features.describe()\n",
        "stats = stats.transpose()\n",
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP_sRTRCgRUm"
      },
      "source": [
        "stats = test_features.describe()\n",
        "stats = stats.transpose()\n",
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHOZyiJ7Hs2H"
      },
      "source": [
        "def norm(x):\n",
        "  stats = x.describe()\n",
        "  stats = stats.transpose()\n",
        "  return (x - stats['mean']) / stats['std']\n",
        "\n",
        "normed_train_features = norm(training_features)\n",
        "normed_test_features = norm(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF3pQYwmgfky"
      },
      "source": [
        "## Build the Input Pipeline for TensorFlow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI1dTJcWpeVL"
      },
      "source": [
        "def feed_input(features_dataframe, target_dataframe, num_of_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_feed_function():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features_dataframe), target_dataframe))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(2000)\n",
        "    dataset = dataset.batch(batch_size).repeat(num_of_epochs)\n",
        "    return dataset\n",
        "  return input_feed_function\n",
        "\n",
        "train_feed_input = feed_input(normed_train_features, training_labels)\n",
        "train_feed_input_testing = feed_input(normed_train_features, training_labels, num_of_epochs=1, shuffle=False)\n",
        "test_feed_input = feed_input(normed_test_features, test_labels, num_of_epochs=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCw3Zh1Vovzf"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpYQHKmqy3--"
      },
      "source": [
        "feature_columns_numeric = [tf.feature_column.numeric_column(m) for m in training_features.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I85mYJ72rFz8"
      },
      "source": [
        "linear_model = LinearRegressor(feature_columns=feature_columns_numeric, optimizer='RMSProp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ebRtr7rIXN"
      },
      "source": [
        "linear_model.train(train_feed_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuCIeITNo_L7"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki_FevrGLCGb"
      },
      "source": [
        "train_predictions = linear_model.predict(train_feed_input_testing)\n",
        "test_predictions = linear_model.predict(test_feed_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfnd5pE2W2iX"
      },
      "source": [
        "train_predictions_series = pd.Series([p['predictions'][0] for p in train_predictions])\n",
        "test_predictions_series = pd.Series([p['predictions'][0] for p in test_predictions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqErzOxZMH67"
      },
      "source": [
        "train_predictions_df = pd.DataFrame(train_predictions_series, columns=['predictions'])\n",
        "test_predictions_df = pd.DataFrame(test_predictions_series, columns=['predictions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1QlGchTypw"
      },
      "source": [
        "training_labels.reset_index(drop=True, inplace=True)\n",
        "train_predictions_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "test_labels.reset_index(drop=True, inplace=True)\n",
        "test_predictions_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPemk9i7Mdgn"
      },
      "source": [
        "train_labels_with_predictions_df = pd.concat([training_labels, train_predictions_df], axis=1)\n",
        "test_labels_with_predictions_df = pd.concat([test_labels, test_predictions_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw2eAJvRwBuo"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAdgDDfxpgMc"
      },
      "source": [
        "def calculate_errors_and_r2(y_true, y_pred):\n",
        "  mean_squared_err = (mean_squared_error(y_true, y_pred))\n",
        "  root_mean_squared_err = np.sqrt(mean_squared_err)\n",
        "  r2 = round(r2_score(y_true, y_pred)*100,0)\n",
        "  return mean_squared_err, root_mean_squared_err, r2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fjo8OZoqOb-"
      },
      "source": [
        "train_mean_squared_error, train_root_mean_squared_error, train_r2_score_percentage = calculate_errors_and_r2(training_labels, train_predictions_series)\n",
        "test_mean_squared_error, test_root_mean_squared_error, test_r2_score_percentage = calculate_errors_and_r2(test_labels, test_predictions_series)\n",
        "\n",
        "print('Training Data Mean Squared Error = ', train_mean_squared_error)\n",
        "print('Training Data Root Mean Squared Error = ', train_root_mean_squared_error)\n",
        "print('Training Data R2 = ', train_r2_score_percentage)\n",
        "\n",
        "print('Test Data Mean Squared Error = ', test_mean_squared_error)\n",
        "print('Test Data Root Mean Squared Error = ', test_root_mean_squared_error)\n",
        "print('Test Data R2 = ', test_r2_score_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
