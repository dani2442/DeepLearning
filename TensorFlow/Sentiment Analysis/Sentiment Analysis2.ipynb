{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data2 = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=data2[data.sentiment!='Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @NancyOsborne180: Last night's debate prove...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@JGreenDC @realDonaldTrump In all fairness #Bi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @WayneDupreeShow: Just woke up to tweet thi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Me reading my family's comments about how grea...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "1   RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "3   RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4   RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5   RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6   RT @warriorwoman91: I liked her and was happy ...  Negative\n",
       "8   Deer in the headlights RT @lizzwinstead: Ben C...  Negative\n",
       "9   RT @NancyOsborne180: Last night's debate prove...  Negative\n",
       "10  @JGreenDC @realDonaldTrump In all fairness #Bi...  Negative\n",
       "11  RT @WayneDupreeShow: Just woke up to tweet thi...  Positive\n",
       "12  Me reading my family's comments about how grea...  Negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 1, 0], dtype=int64),\n",
       " Index(['Positive', 'Negative'], dtype='object'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_label=data3.sentiment.factorize()\n",
    "sentiment_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tweet = data3.text.values # select tweets\n",
    "tokenizer = Tokenizer(num_words=5000) # Create tokenizer with max numbers 5000\n",
    "tokenizer.fit_on_texts(tweet) # initialize tokenizer on our tweets\n",
    "vocab_size = len(tokenizer.word_index) + 1 # vocab size\n",
    "encoded_docs = tokenizer.texts_to_sequences(tweet) # tweets applied to our tokenizer\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200) # tweets with 200 len, for lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfFâ€¦\n",
      "[3, 365, 135, 2459, 1, 716, 2, 45, 65, 258, 42, 215, 7, 4368, 177, 1794, 18, 1339, 1430, 761, 13, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "print(tweet[0])\n",
    "print(encoded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                16600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 176,651\n",
      "Trainable params: 176,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(5000, embedding_vector_length, input_length=200) )\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', \n",
    "                           metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "269/269 [==============================] - 26s 97ms/step - loss: 0.4652 - accuracy: 0.8060 - val_loss: 0.4004 - val_accuracy: 0.8234\n",
      "Epoch 2/5\n",
      "269/269 [==============================] - 26s 96ms/step - loss: 0.3087 - accuracy: 0.8692 - val_loss: 0.3251 - val_accuracy: 0.8616\n",
      "Epoch 3/5\n",
      "269/269 [==============================] - 26s 96ms/step - loss: 0.2536 - accuracy: 0.8957 - val_loss: 0.3529 - val_accuracy: 0.8588\n",
      "Epoch 4/5\n",
      "269/269 [==============================] - 25s 94ms/step - loss: 0.2204 - accuracy: 0.9066 - val_loss: 0.3530 - val_accuracy: 0.8635\n",
      "Epoch 5/5\n",
      "269/269 [==============================] - 25s 93ms/step - loss: 0.1966 - accuracy: 0.9203 - val_loss: 0.3741 - val_accuracy: 0.8719\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequence,sentiment_label[0],\n",
    "                  validation_split=0.2, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word =\"This is very happy\"\n",
    "tw = tokenizer.texts_to_sequences([test_word])\n",
    "tw = pad_sequences(tw,maxlen=200)\n",
    "prediction = int(model.predict(tw).round().item())\n",
    "sentiment_label[1][prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
